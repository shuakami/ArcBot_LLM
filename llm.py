import re
from storage.history import save_conversation_history, load_conversation_history
from llm_api import get_ai_response
from context_utils import build_context_within_limit
from storage.notebook import DEFAULT_ROLE_KEY
from storage.napcat_history import napcat_history_manager
from logger import log, log_llm_context
from core.prompt_builder import build_system_prompt


def process_conversation(chat_id, user_input, chat_type="private", active_role_name=None, self_id=None):
    log.debug(f"LLM: å¼€å§‹ process_conversation, chat_id={chat_id}, chat_type={chat_type}, active_role_name='{active_role_name}'")
    
    try:
        # 1. ç¡®å®šæœ¬æ¬¡å¯¹è¯æ‰€å±çš„è§’è‰²
        role_key = active_role_name if active_role_name else DEFAULT_ROLE_KEY
        log.debug(f"LLM: æœ¬è½®å¯¹è¯ role_key ç¡®å®šä¸º: '{role_key}'")

        # 2. æ„å»ºç³»ç»Ÿæç¤º
        log.debug(f"LLM: å‡†å¤‡æ„å»º system_prompt, ä¼ å…¥ active_role_name='{active_role_name}'")
        system_prompt_content = build_system_prompt(chat_id, chat_type, active_role_name=active_role_name)
        system_message = {"role": "system", "content": system_prompt_content}
        log.debug("LLM: system_prompt æ„å»ºå®Œæˆ")

        # 3. åŠ è½½æ­¤è§’è‰²ä¸“å±çš„å†å²è®°å½•
        log.debug(f"LLM: å‡†å¤‡åŠ è½½å†å²è®°å½•, ä¼ å…¥ active_role_name='{active_role_name}'")
        history = load_conversation_history(chat_id, chat_type, active_role_name=active_role_name)
        log.debug(f"LLM: å†å²è®°å½•åŠ è½½å®Œæˆ, å…± {len(history)} æ¡")
        
        # ç¡®ä¿system promptæ˜¯æœ€æ–°çš„
        if history and history[0]['role'] == 'system':
            history[0] = system_message
            log.debug("LLM: æ›´æ–°äº†å†å²è®°å½•ä¸­çš„ system_prompt")
        else:
            history.insert(0, system_message)
            log.debug("LLM: åœ¨å†å²è®°å½•å¼€å¤´æ’å…¥äº†æ–°çš„ system_prompt")
            
        # 4. æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        user_message = {"role": "user", "content": user_input, "role_marker": role_key}
        history.append(user_message)
        log.debug(f"LLM: æ·»åŠ äº†ç”¨æˆ·æ–°æ¶ˆæ¯, å½“å‰å†å²å…± {len(history)} æ¡")

        # 5. å¤„ç†å¯¹è¯ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨é‡æ–°è¯·æ±‚ï¼‰
        yield from _process_conversation_with_tools(history, role_key, chat_id, chat_type, active_role_name, self_id)

    except Exception:
        log.error("AIå“åº”å‡ºé”™", exc_info=True)
        yield "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶é‡åˆ°äº†å†…éƒ¨é”™è¯¯ã€‚"
        return


def _process_conversation_with_tools(history, role_key, chat_id, chat_type, active_role_name, self_id, max_retries=3):
    """å¤„ç†å¯¹è¯ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨åçš„é‡æ–°è¯·æ±‚"""
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # æ„å»ºå¹¶å‘é€ä¸Šä¸‹æ–‡åˆ°AI
            context_to_send = build_context_within_limit(history, active_role=role_key)
            log.debug("LLM: å¼€å§‹æ„å»ºå‘é€åˆ°AIçš„æœ€ç»ˆä¸Šä¸‹æ–‡")
            log_llm_context(context_to_send)
            
            # å¤„ç† AI å“åº”æµ
            full_response = ""
            response_segments = []
            has_tool_call = False
            log.debug("LLM: å¼€å§‹è°ƒç”¨AIæ¥å£...")
            
            for segment in get_ai_response(context_to_send):
                response_segments.append(segment)
                full_response = "".join(response_segments)
                
                # å®æ—¶æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼Œå¦‚æœæœ‰å°±ä¸ç»§ç»­è¾“å‡º
                tool_info = _check_for_tool_calls_sync(full_response, chat_id, chat_type, active_role_name, self_id)
                if tool_info is not None:
                    tool_type = tool_info.get("type", "unknown")
                    log.info(f"LLM: æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {tool_type}")
                    
                    # è®°å½•AIçš„å·¥å…·è°ƒç”¨å›å¤ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨æ ‡è®°çš„é‚£æ¡ï¼‰
                    ai_tool_message = {"role": "assistant", "content": full_response, "role_marker": role_key}
                    history.append(ai_tool_message)
                    
                    # æ‰§è¡Œå®é™…çš„å·¥å…·è°ƒç”¨å¹¶è·å–æ•°æ®
                    try:
                        context_data = _execute_tool_call(tool_info)
                        if context_data:
                            # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœä½œä¸ºç³»ç»Ÿæ¶ˆæ¯
                            tool_call_message = {
                                "role": "system", 
                                "content": f"[ç³»ç»Ÿå†…éƒ¨] ä»¥ä¸‹æ˜¯è·å–åˆ°çš„ç›¸å…³è®°å½•ï¼š\n{context_data}\n\nç°åœ¨è¯·ä½ åŸºäºè¿™äº›å†å²ä¿¡æ¯ï¼Œç”¨è‡ªç„¶çš„å¯¹è¯æ–¹å¼å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\nã€ä¸¥æ ¼ç¦æ­¢å¤è¯»ã€‘ä»¥ä¸‹å†…å®¹ç»å¯¹ä¸èƒ½å‡ºç°åœ¨ä½ çš„å›å¤ä¸­ï¼š\n1. ä»»ä½•[ç³»ç»Ÿå†…éƒ¨]ã€ã€è·å–åˆ°çš„èŠå¤©ä¸Šä¸‹æ–‡ã€‘ã€ã€æœç´¢ç»“æœã€‘ã€ã€æœç´¢ç»“æŸã€‘ã€ã€ä¸Šä¸‹æ–‡ç»“æŸã€‘ç­‰ç³»ç»Ÿæ ‡è®°\n2. ä»»ä½•[ç”¨æˆ·:xxx]ã€[ç¾¤:xxx]ã€[æ—¶é—´:xxx]æ ¼å¼çš„åŸå§‹è®°å½•\n3. å½“å‰ç”¨æˆ·è¾“å…¥çš„é‡å¤å†…å®¹\n4. è¿™äº›å†å²è®°å½•çš„åŸå§‹æ ¼å¼åŒ–å†…å®¹æˆ–ç³»ç»Ÿæ³¨å…¥çš„æ–‡æœ¬\n5. ä»»ä½•å·¥å…·è°ƒç”¨ç›¸å…³çš„ä¿¡æ¯æˆ–æ ¼å¼åŒ–è¾“å‡º\n6. ç›¸å…³åº¦æ•°å­—ã€æ—¶é—´æˆ³ç­‰æœç´¢ç»“æœçš„æŠ€æœ¯ä¿¡æ¯\n\nã€æ­£ç¡®åšæ³•ã€‘è¯·åŸºäºä¸Šè¿°å†å²ä¿¡æ¯ï¼Œä»¥Sakiå’ŒNyaçš„è‡ªç„¶å¯¹è¯å½¢å¼å›ç­”ï¼Œå°±åƒå¥¹ä»¬å›å¿†èµ·äº†ç›¸å…³å†…å®¹ä¸€æ ·ï¼Œä¸è¦æåŠä»»ä½•ç³»ç»Ÿæ ‡è®°æˆ–æ ¼å¼åŒ–ä¿¡æ¯ã€‚",
                                "role_marker": role_key
                            }
                            history.append(tool_call_message)
                            
                            retry_count += 1
                            has_tool_call = True
                            log.info(f"LLM: å·¥å…·è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹ç¬¬ {retry_count} æ¬¡é‡æ–°è¯·æ±‚")
                            break  # è·³å‡ºå½“å‰å“åº”å¾ªç¯ï¼Œé‡æ–°å¼€å§‹
                        else:
                            log.warning("LLM: å·¥å…·è°ƒç”¨æœªè¿”å›æ•°æ®ï¼Œç»§ç»­æ­£å¸¸è¾“å‡º")
                    except Exception as e:
                        log.error(f"LLM: å·¥å…·è°ƒç”¨æ‰§è¡Œå¤±è´¥: {e}")
                        # å·¥å…·è°ƒç”¨å¤±è´¥æ—¶ï¼Œç»§ç»­æ­£å¸¸è¾“å‡ºï¼Œä¸é‡æ–°è¯·æ±‚
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ­£å¸¸è¾“å‡º
                    yield segment
            
            # å¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œé‡æ–°å¼€å§‹å¾ªç¯
            if has_tool_call:
                # åœ¨é‡æ–°è¯·æ±‚å‰ï¼Œå…ˆä¿å­˜åŒ…å«å·¥å…·è°ƒç”¨çš„å†å²è®°å½•
                log.debug(f"LLM: å·¥å…·è°ƒç”¨åä¿å­˜å†å²è®°å½•, ä¼ å…¥ active_role_name='{active_role_name}', å…± {len(history)} æ¡")
                save_conversation_history(
                    chat_id, 
                    history, 
                    chat_type, 
                    active_role_name=active_role_name
                )
                log.info("ğŸ’¾ å·¥å…·è°ƒç”¨å†å²å·²ä¿å­˜")
                continue
                
            log.debug(f"LLM: AIå›å¤å®Œæˆ, æ€»é•¿åº¦: {len(full_response)}")
            
            # ä¿å­˜å†å²è®°å½•
            if full_response:
                ai_message = {"role": "assistant", "content": full_response, "role_marker": role_key}
                history.append(ai_message)
                log.debug(f"LLM: å‡†å¤‡ä¿å­˜å†å²è®°å½•, ä¼ å…¥ active_role_name='{active_role_name}', å…± {len(history)} æ¡")
                
                save_conversation_history(
                    chat_id, 
                    history, 
                    chat_type, 
                    active_role_name=active_role_name
                )
                log.info("ğŸ’¾ å¯¹è¯å†å²å·²ä¿å­˜")
            
            # æˆåŠŸå®Œæˆï¼Œè·³å‡ºå¾ªç¯
            break
            
        except Exception as e:
            log.error(f"LLM: ç¬¬ {retry_count + 1} æ¬¡å¤„ç†å¤±è´¥: {e}")
            retry_count += 1
            if retry_count >= max_retries:
                yield "æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•åä»ç„¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
                return


async def _check_for_tool_calls_async(text: str, chat_id: str, chat_type: str, active_role_name: str = None, self_id: str = None):
    """
    å¼‚æ­¥ç‰ˆæœ¬çš„å·¥å…·è°ƒç”¨æ£€æµ‹å‡½æ•°
    è¿”å›: (context_data, tool_info) å¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œå¦åˆ™è¿”å› (None, None)
    """
    # 1. æ£€æŸ¥ get_context å·¥å…·è°ƒç”¨
    get_context_pattern = r'\[get_context:(\d+)\]'
    get_match = re.search(get_context_pattern, text)
    
    if get_match:
        count = int(get_match.group(1))
        log.info(f"LLM: æ£€æµ‹åˆ°get_contextå·¥å…·è°ƒç”¨ï¼Œè¯·æ±‚ {count} æ¡ä¸Šä¸‹æ–‡æ¶ˆæ¯")
        
        try:
            # é€šè¿‡Napcat APIè·å–æœ€è¿‘çš„æ¶ˆæ¯
            recent_messages = await napcat_history_manager.get_recent_messages(
                chat_id, count, exclude_self=True, self_id=self_id
            )
            
            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            context_data = napcat_history_manager.format_context_for_ai(recent_messages)
            log.debug(f"LLM: è·å–åˆ°ä¸Šä¸‹æ–‡: {context_data[:200]}...")
            
            return context_data, {"type": "get_context", "count": count}
            
        except Exception as e:
            log.error(f"LLM: è·å–ä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")
            return None, None
    
    # 2. æ£€æŸ¥ search_context å·¥å…·è°ƒç”¨
    # æ”¯æŒæ ¼å¼: [search_context:å…³é”®è¯] æˆ– [search_context:å…³é”®è¯:å¤©æ•°]
    search_pattern = r'\[search_context:([^:\]]+)(?::(\d+))?\]'
    search_match = re.search(search_pattern, text)
    
    if search_match:
        query = search_match.group(1).strip()
        days = int(search_match.group(2)) if search_match.group(2) else 7  # é»˜è®¤7å¤©
        
        # é™åˆ¶æœç´¢èŒƒå›´
        days = max(7, min(730, days))  # 7å¤©åˆ°2å¹´
        
        log.info(f"LLM: æ£€æµ‹åˆ°search_contextå·¥å…·è°ƒç”¨ï¼Œæœç´¢ '{query}'ï¼ŒèŒƒå›´ {days} å¤©")
        
        try:
            # æœç´¢èŠå¤©è®°å½•
            search_results = await napcat_history_manager.search_context(
                chat_id, query, days=days, max_results=15, self_id=self_id
            )
            
            log.debug(f"LLM: æœç´¢å®Œæˆ: {search_results[:200]}...")
            
            return search_results, {"type": "search_context", "query": query, "days": days}
            
        except Exception as e:
            log.error(f"LLM: æœç´¢èŠå¤©è®°å½•æ—¶å‡ºé”™: {e}")
            return None, None
    
    return None, None


def _check_for_tool_calls_sync(text: str, chat_id: str, chat_type: str, active_role_name: str = None, self_id: str = None):
    """
    åŒæ­¥ç‰ˆæœ¬çš„å·¥å…·è°ƒç”¨æ£€æµ‹å‡½æ•°
    è¿”å›: (tool_info) å¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œå¦åˆ™è¿”å› None
    æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°åªåšæ£€æµ‹ï¼Œä¸æ‰§è¡Œå®é™…çš„APIè°ƒç”¨
    """
    # æ£€æŸ¥ get_context å·¥å…·è°ƒç”¨
    get_pattern = r'\[get_context:(\d+)\]'
    get_match = re.search(get_pattern, text)
    
    if get_match:
        count = int(get_match.group(1))
        log.info(f"LLM: æ£€æµ‹åˆ°get_contextå·¥å…·è°ƒç”¨ï¼Œè¯·æ±‚ {count} æ¡ä¸Šä¸‹æ–‡æ¶ˆæ¯")
        return {"type": "get_context", "count": count, "chat_id": chat_id, "self_id": self_id}
    
    # æ£€æŸ¥ search_context å·¥å…·è°ƒç”¨
    # æ”¯æŒæ ¼å¼: [search_context:å…³é”®è¯] æˆ– [search_context:å…³é”®è¯:å¤©æ•°]
    search_pattern = r'\[search_context:([^:\]]+)(?::(\d+))?\]'
    search_match = re.search(search_pattern, text)
    
    if search_match:
        query = search_match.group(1).strip()
        days = int(search_match.group(2)) if search_match.group(2) else 7  # é»˜è®¤7å¤©
        
        # é™åˆ¶æœç´¢èŒƒå›´
        days = max(7, min(730, days))  # 7å¤©åˆ°2å¹´
        
        log.info(f"LLM: æ£€æµ‹åˆ°search_contextå·¥å…·è°ƒç”¨ï¼Œæœç´¢ '{query}'ï¼ŒèŒƒå›´ {days} å¤©")
        return {"type": "search_context", "query": query, "days": days, "chat_id": chat_id, "self_id": self_id}
    
    return None


def _execute_tool_call(tool_info):
    """
    æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœæ•°æ®
    è¿”å›: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    import asyncio
    
    tool_type = tool_info.get("type")
    chat_id = tool_info.get("chat_id")
    self_id = tool_info.get("self_id")
    
    try:
        if tool_type == "get_context":
            count = tool_info.get("count", 20)
            log.debug(f"LLM: æ‰§è¡Œget_contextå·¥å…·è°ƒç”¨ï¼Œè·å– {count} æ¡æ¶ˆæ¯")
            
            # ç›´æ¥åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œï¼Œé¿å…åˆ›å»ºæ–°çº¿ç¨‹å’Œäº‹ä»¶å¾ªç¯
            # è¿™æ ·WebSocketå“åº”å¯ä»¥æ­£ç¡®ä¼ é€’åˆ°waitingåç¨‹
            try:
                import nest_asyncio
                nest_asyncio.apply()  # å…è®¸åµŒå¥—äº‹ä»¶å¾ªç¯
            except ImportError:
                log.warning("nest_asyncioä¸å¯ç”¨ï¼Œå¯èƒ½å‡ºç°äº‹ä»¶å¾ªç¯åµŒå¥—é—®é¢˜")
            
            async def get_context():
                recent_messages = await napcat_history_manager.get_recent_messages(
                    chat_id, count, exclude_self=True, self_id=self_id
                )
                return napcat_history_manager.format_context_for_ai(recent_messages)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­
            try:
                loop = asyncio.get_running_loop()
                # å¦‚æœå·²åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨ nest_asyncio æ”¯æŒåµŒå¥—
                log.info(f"LLM: æ£€æµ‹åˆ°è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨åµŒå¥—æ‰§è¡Œ")
                return loop.run_until_complete(get_context())
                    
            except RuntimeError:
                # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ asyncio.run
                log.info(f"LLM: æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯")
                return asyncio.run(get_context())
            
        elif tool_type == "search_context":
            query = tool_info.get("query", "")
            days = tool_info.get("days", 7)
            log.debug(f"LLM: æ‰§è¡Œsearch_contextå·¥å…·è°ƒç”¨ï¼Œæœç´¢ '{query}'ï¼ŒèŒƒå›´ {days} å¤©")
            
            async def search_context():
                return await napcat_history_manager.search_context(
                    chat_id, query, days=days, max_results=15, self_id=self_id
                )
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­
            try:
                loop = asyncio.get_running_loop()
                # å¦‚æœå·²åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨ nest_asyncio æ”¯æŒåµŒå¥—
                log.info(f"LLM: æ£€æµ‹åˆ°è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨åµŒå¥—æ‰§è¡Œæœç´¢")
                return loop.run_until_complete(search_context())
                    
            except RuntimeError:
                # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ asyncio.run
                log.info(f"LLM: æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯è¿›è¡Œæœç´¢")
                return asyncio.run(search_context())
            
        else:
            log.warning(f"LLM: æœªçŸ¥çš„å·¥å…·è°ƒç”¨ç±»å‹: {tool_type}")
            return None
            
    except Exception as e:
        log.error(f"LLM: æ‰§è¡Œå·¥å…·è°ƒç”¨æ—¶å‡ºé”™: {e}")
        return None
